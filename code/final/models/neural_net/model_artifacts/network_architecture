digraph {
	graph [size="21.15,21.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	135471845211856 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	135476368765040 -> 135471845211936 [dir=none]
	135471845211936 [label="mat1
 (1, 32)" fillcolor=orange]
	135476368765040 -> 135471848753024 [dir=none]
	135471848753024 [label="mat2
 (32, 1)" fillcolor=orange]
	135476368765040 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (1, 32)
mat1_sym_strides:        (32, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :        (32, 1)
mat2_sym_strides:        (1, 32)"]
	135471848975920 -> 135476368765040
	135471845210016 [label="layer4.bias
 (1)" fillcolor=lightblue]
	135471845210016 -> 135471848975920
	135471848975920 [label=AccumulateGrad]
	135471849362992 -> 135476368765040
	135471849362992 -> 135471845769376 [dir=none]
	135471845769376 [label="result
 (1, 32)" fillcolor=orange]
	135471849362992 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	135471849367408 -> 135471849362992
	135471849367408 -> 135471845210256 [dir=none]
	135471845210256 [label="input
 (1, 32)" fillcolor=orange]
	135471849367408 -> 135471845769616 [dir=none]
	135471845769616 [label="result1
 (32)" fillcolor=orange]
	135471849367408 -> 135471853514464 [dir=none]
	135471853514464 [label="result2
 (32)" fillcolor=orange]
	135471849367408 -> 135471845197936 [dir=none]
	135471845197936 [label="running_mean
 (32)" fillcolor=orange]
	135471849367408 -> 135471845209216 [dir=none]
	135471845209216 [label="running_var
 (32)" fillcolor=orange]
	135471849367408 -> 135471845209456 [dir=none]
	135471845209456 [label="weight
 (32)" fillcolor=orange]
	135471849367408 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	135471849363856 -> 135471849367408
	135471849363856 -> 135471845211776 [dir=none]
	135471845211776 [label="mat1
 (1, 64)" fillcolor=orange]
	135471849363856 -> 135471845769536 [dir=none]
	135471845769536 [label="mat2
 (64, 32)" fillcolor=orange]
	135471849363856 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (1, 64)
mat1_sym_strides:        (64, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 32)
mat2_sym_strides:        (1, 64)"]
	135471849363952 -> 135471849363856
	135471845209376 [label="layer3.bias
 (32)" fillcolor=lightblue]
	135471845209376 -> 135471849363952
	135471849363952 [label=AccumulateGrad]
	135471849367696 -> 135471849363856
	135471849367696 -> 135471845770176 [dir=none]
	135471845770176 [label="result
 (1, 64)" fillcolor=orange]
	135471849367696 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	135471849368032 -> 135471849367696
	135471849368032 -> 135471845209136 [dir=none]
	135471845209136 [label="input
 (1, 64)" fillcolor=orange]
	135471849368032 -> 135471845770416 [dir=none]
	135471845770416 [label="result1
 (64)" fillcolor=orange]
	135471849368032 -> 135471845770336 [dir=none]
	135471845770336 [label="result2
 (64)" fillcolor=orange]
	135471849368032 -> 135471845211616 [dir=none]
	135471845211616 [label="running_mean
 (64)" fillcolor=orange]
	135471849368032 -> 135471845198656 [dir=none]
	135471845198656 [label="running_var
 (64)" fillcolor=orange]
	135471849368032 -> 135471845208816 [dir=none]
	135471845208816 [label="weight
 (64)" fillcolor=orange]
	135471849368032 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	135471849367312 -> 135471849368032
	135471849367312 -> 135471845209776 [dir=none]
	135471845209776 [label="mat1
 (1, 128)" fillcolor=orange]
	135471849367312 -> 135471845769776 [dir=none]
	135471845769776 [label="mat2
 (128, 64)" fillcolor=orange]
	135471849367312 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 128)
mat1_sym_strides:       (128, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (128, 64)
mat2_sym_strides:       (1, 128)"]
	135471849367840 -> 135471849367312
	135471845208736 [label="layer2.bias
 (64)" fillcolor=lightblue]
	135471845208736 -> 135471849367840
	135471849367840 [label=AccumulateGrad]
	135471849367552 -> 135471849367312
	135471849367552 -> 135471845770896 [dir=none]
	135471845770896 [label="result
 (1, 128)" fillcolor=orange]
	135471849367552 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	135471849368128 -> 135471849367552
	135471849368128 -> 135471853097184 [dir=none]
	135471853097184 [label="input
 (1, 128)" fillcolor=orange]
	135471849368128 -> 135471845771136 [dir=none]
	135471845771136 [label="result1
 (128)" fillcolor=orange]
	135471849368128 -> 135471845771056 [dir=none]
	135471845771056 [label="result2
 (128)" fillcolor=orange]
	135471849368128 -> 135471845210096 [dir=none]
	135471845210096 [label="running_mean
 (128)" fillcolor=orange]
	135471849368128 -> 135471853098304 [dir=none]
	135471853098304 [label="running_var
 (128)" fillcolor=orange]
	135471849368128 -> 135471845199056 [dir=none]
	135471845199056 [label="weight
 (128)" fillcolor=orange]
	135471849368128 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	135471849367360 -> 135471849368128
	135471849367360 -> 135471845209856 [dir=none]
	135471845209856 [label="mat1
 (1, 66)" fillcolor=orange]
	135471849367360 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (1, 66)
mat1_sym_strides:             ()
mat2            :           None
mat2_sym_sizes  :      (66, 128)
mat2_sym_strides:        (1, 66)"]
	135471849368656 -> 135471849367360
	135471845200256 [label="layer1.bias
 (128)" fillcolor=lightblue]
	135471845200256 -> 135471849368656
	135471849368656 [label=AccumulateGrad]
	135471849370816 -> 135471849367360
	135471849370816 [label=TBackward0]
	135471849368944 -> 135471849370816
	135471845199456 [label="layer1.weight
 (128, 66)" fillcolor=lightblue]
	135471845199456 -> 135471849368944
	135471849368944 [label=AccumulateGrad]
	135471849371200 -> 135471849368128
	135471845199056 [label="bn1.weight
 (128)" fillcolor=lightblue]
	135471845199056 -> 135471849371200
	135471849371200 [label=AccumulateGrad]
	135471849368416 -> 135471849368128
	135471845199936 [label="bn1.bias
 (128)" fillcolor=lightblue]
	135471845199936 -> 135471849368416
	135471849368416 [label=AccumulateGrad]
	135471849373648 -> 135471849367312
	135471849373648 [label=TBackward0]
	135471853409600 -> 135471849373648
	135471845200736 [label="layer2.weight
 (64, 128)" fillcolor=lightblue]
	135471845200736 -> 135471853409600
	135471853409600 [label=AccumulateGrad]
	135471849367936 -> 135471849368032
	135471845208816 [label="bn2.weight
 (64)" fillcolor=lightblue]
	135471845208816 -> 135471849367936
	135471849367936 [label=AccumulateGrad]
	135471849367984 -> 135471849368032
	135471845208896 [label="bn2.bias
 (64)" fillcolor=lightblue]
	135471845208896 -> 135471849367984
	135471849367984 [label=AccumulateGrad]
	135471849367504 -> 135471849363856
	135471849367504 [label=TBackward0]
	135471849371152 -> 135471849367504
	135471845209296 [label="layer3.weight
 (32, 64)" fillcolor=lightblue]
	135471845209296 -> 135471849371152
	135471849371152 [label=AccumulateGrad]
	135471849368080 -> 135471849367408
	135471845209456 [label="bn3.weight
 (32)" fillcolor=lightblue]
	135471845209456 -> 135471849368080
	135471849368080 [label=AccumulateGrad]
	135471849367648 -> 135471849367408
	135471845209536 [label="bn3.bias
 (32)" fillcolor=lightblue]
	135471845209536 -> 135471849367648
	135471849367648 [label=AccumulateGrad]
	135471849367744 -> 135476368765040
	135471849367744 [label=TBackward0]
	135471849363616 -> 135471849367744
	135471845209936 [label="layer4.weight
 (1, 32)" fillcolor=lightblue]
	135471845209936 -> 135471849363616
	135471849363616 [label=AccumulateGrad]
	135476368765040 -> 135471845211856
}
