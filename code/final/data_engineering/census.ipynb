{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8148a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4524e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDIAN_HOUSEHOLD_INCOME</th>\n",
       "      <td>36711.000000</td>\n",
       "      <td>44861.000000</td>\n",
       "      <td>46288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP_POVERTY_DETERMINED</th>\n",
       "      <td>10380.000000</td>\n",
       "      <td>302057.000000</td>\n",
       "      <td>469463.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP_BELOW_POVERTY</th>\n",
       "      <td>2262.000000</td>\n",
       "      <td>50175.000000</td>\n",
       "      <td>76141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP_16_PLUS</th>\n",
       "      <td>8680.000000</td>\n",
       "      <td>240096.000000</td>\n",
       "      <td>382682.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POP_UNEMPLOYED</th>\n",
       "      <td>4258.000000</td>\n",
       "      <td>78349.000000</td>\n",
       "      <td>125748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLDS_TOTAL</th>\n",
       "      <td>4464.000000</td>\n",
       "      <td>118117.000000</td>\n",
       "      <td>192064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLDS_SNAP</th>\n",
       "      <td>571.000000</td>\n",
       "      <td>15819.000000</td>\n",
       "      <td>20913.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POVERTY_RATE</th>\n",
       "      <td>21.791908</td>\n",
       "      <td>16.611103</td>\n",
       "      <td>16.218744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNEMPLOYMENT_RATE</th>\n",
       "      <td>49.055300</td>\n",
       "      <td>32.632364</td>\n",
       "      <td>32.859659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNAP_RECEIPT_RATE</th>\n",
       "      <td>12.791219</td>\n",
       "      <td>13.392653</td>\n",
       "      <td>10.888558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0              1              2\n",
       "YEAR                      2011.000000    2011.000000    2011.000000\n",
       "STATE_FIPS                  37.000000      37.000000      37.000000\n",
       "COUNTY_FIPS                 43.000000      51.000000      81.000000\n",
       "MEDIAN_HOUSEHOLD_INCOME  36711.000000   44861.000000   46288.000000\n",
       "POP_POVERTY_DETERMINED   10380.000000  302057.000000  469463.000000\n",
       "POP_BELOW_POVERTY         2262.000000   50175.000000   76141.000000\n",
       "POP_16_PLUS               8680.000000  240096.000000  382682.000000\n",
       "POP_UNEMPLOYED            4258.000000   78349.000000  125748.000000\n",
       "HOUSEHOLDS_TOTAL          4464.000000  118117.000000  192064.000000\n",
       "HOUSEHOLDS_SNAP            571.000000   15819.000000   20913.000000\n",
       "POVERTY_RATE                21.791908      16.611103      16.218744\n",
       "UNEMPLOYMENT_RATE           49.055300      32.632364      32.859659\n",
       "SNAP_RECEIPT_RATE           12.791219      13.392653      10.888558"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/economic.csv')\n",
    "df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272c5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cbp09co.txt (Year: 2009)...\n",
      "Processing cbp10co.txt (Year: 2010)...\n",
      "Processing cbp11co.txt (Year: 2011)...\n",
      "Processing cbp12co.txt (Year: 2012)...\n",
      "Processing cbp13co.txt (Year: 2013)...\n",
      "Processing cbp14co.txt (Year: 2014)...\n",
      "Processing cbp15co.txt (Year: 2015)...\n",
      "Processing cbp16co.txt (Year: 2016)...\n",
      "Processing cbp17co.txt (Year: 2017)...\n",
      "Processing cbp18co.txt (Year: 2018)...\n",
      "Processing cbp19co.txt (Year: 2019)...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'rename'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[32m     89\u001b[39m df = combine_cbp_data(\u001b[33m'\u001b[39m\u001b[33m../../data/cbp\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     90\u001b[39m column_mapping = {\n\u001b[32m     91\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFIPSTATE\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mState_FIPS\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFIPSCTY\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCounty_FIPS\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCENCTY\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCensus_County_Code\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    117\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrename\u001b[49m(columns=column_mapping)\n\u001b[32m    119\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33m../../combined_cbp.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'rename'"
     ]
    }
   ],
   "source": [
    "def combine_cbp_data(directory='.', output_file='cbp_data.csv'):\n",
    "    \"\"\"\n",
    "    Reads all cbpYYco.txt files in the specified directory,\n",
    "    adds a 'YEAR' column, and combines them into a single DataFrame.\n",
    "    \"\"\"\n",
    "    # Pattern to match files like cbp07co.txt, cbp14co.txt in the directory\n",
    "    file_pattern = os.path.join(directory, 'cbp??co.txt')\n",
    "    files = glob.glob(file_pattern)\n",
    "\n",
    "    if not files:\n",
    "        print(f\"No files found matching pattern 'cbp??co.txt' in '{directory}'\")\n",
    "        return None\n",
    "\n",
    "    # Define dtype mapping to preserve leading zeros in FIPS codes\n",
    "    dtype_map = {\n",
    "        'FIPSTATE': str,\n",
    "        'FIPSCTY': str,\n",
    "        'CENSTATE': str,\n",
    "        'CENCTY': str,\n",
    "        'NAICS': str,\n",
    "        'FIPSTATE'.lower(): str,\n",
    "        'FIPSCTY'.lower(): str,\n",
    "        'CENSTATE'.lower(): str,\n",
    "        'CENCTY'.lower(): str,\n",
    "        'NAICS'.lower(): str\n",
    "    }\n",
    "\n",
    "    column_mapping = {\n",
    "        \"FIPSTATE\": \"State_FIPS\",\n",
    "        \"FIPSCTY\": \"County_FIPS\",\n",
    "        \"NAICS\": \"NAICS_Industry_Code\",\n",
    "        \"EMPFLAG\": \"Emp_Suppression_Flag\",\n",
    "        \"EMP_NF\": \"Emp_Noise_Flag\",\n",
    "        \"EMP\": \"Total_Employees\",\n",
    "        \"QP1_NF\": \"Q1_Payroll_Noise_Flag\",\n",
    "        \"QP1\": \"Q1_Payroll_1000s\",\n",
    "        \"AP_NF\": \"Annual_Payroll_Noise_Flag\",\n",
    "        \"AP\": \"Annual_Payroll_1000s\",\n",
    "        \"EST\": \"Total_Establishments\",\n",
    "        \"N1_4\": \"Est_1_to_4_Emp\",\n",
    "        \"N<5\": \"Est_1_to_4_Emp\",       # Handling the 2017+ schema change\n",
    "        \"N5_9\": \"Est_5_to_9_Emp\",\n",
    "        \"N10_19\": \"Est_10_to_19_Emp\",\n",
    "        \"N20_49\": \"Est_20_to_49_Emp\",\n",
    "        \"N50_99\": \"Est_50_to_99_Emp\",\n",
    "        \"N100_249\": \"Est_100_to_249_Emp\",\n",
    "        \"N250_499\": \"Est_250_to_499_Emp\",\n",
    "        \"N500_999\": \"Est_500_to_999_Emp\",\n",
    "        \"N1000\": \"Est_1000_Plus_Emp\",\n",
    "        \"N1000_1\": \"Est_1000_to_1499_Emp\",\n",
    "        \"N1000_2\": \"Est_1500_to_2499_Emp\",\n",
    "        \"N1000_3\": \"Est_2500_to_4999_Emp\",\n",
    "        \"N1000_4\": \"Est_5000_Plus_Emp\",\n",
    "        \"CENSTATE\": \"Census_State_Code\",\n",
    "        \"CENCTY\": \"Census_County_Code\"\n",
    "    }\n",
    "\n",
    "    for filepath in sorted(files):\n",
    "        filename = os.path.basename(filepath)\n",
    "        try:\n",
    "            # Extract 2-digit year from 'cbpYYco.txt' (indices 3 and 4)\n",
    "            yy = filename[3:5]\n",
    "            year = 2000 + int(yy)\n",
    "            \n",
    "            print(f\"Processing {filename} (Year: {year})...\")\n",
    "\n",
    "            # Read the CSV\n",
    "            # Remove dtype_map from read_csv to avoid mismatch issues if headers are lowercase\n",
    "            df = pd.read_csv(filepath, encoding='latin1', low_memory=True, dtype=dtype_map)\n",
    "            df.columns = df.columns.str.upper()\n",
    "            df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "            # Add context columns\n",
    "            df['YEAR'] = year\n",
    "            \n",
    "            # Create full FIPS code (State + County)\n",
    "            # Force conversion to string (.astype(str)) before using .str accessor\n",
    "            if 'FIPSTATE' in df.columns and 'FIPSCTY' in df.columns:\n",
    "                df['FIPS'] = df['FIPSTATE'].astype(str).str.zfill(2) + df['FIPSCTY'].astype(str).str.zfill(3)\n",
    "\n",
    "            file_exists = os.path.exists(output_file)\n",
    "            df.to_csv(output_file, mode='a', index=False, header=not file_exists)\n",
    "            del df\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "combine_cbp_data('../../data/cbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ac2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Processing samples: 0 to 100000\n",
      "Processing samples: 100000 to 200000\n",
      "Processing samples: 200000 to 300000\n",
      "Processing samples: 300000 to 400000\n",
      "Processing samples: 400000 to 500000\n",
      "Processing samples: 500000 to 600000\n",
      "Processing samples: 600000 to 700000\n",
      "Processing samples: 700000 to 800000\n",
      "Processing samples: 800000 to 900000\n",
      "Processing samples: 900000 to 1000000\n",
      "Processing samples: 1000000 to 1100000\n",
      "Processing samples: 1100000 to 1200000\n",
      "Processing samples: 1200000 to 1300000\n",
      "Processing samples: 1300000 to 1400000\n",
      "Processing samples: 1400000 to 1500000\n",
      "Processing samples: 1500000 to 1600000\n",
      "Processing samples: 1600000 to 1700000\n",
      "Processing samples: 1700000 to 1800000\n",
      "Processing samples: 1800000 to 1900000\n",
      "Processing samples: 1900000 to 2000000\n",
      "Processing samples: 2000000 to 2100000\n",
      "Processing samples: 2100000 to 2200000\n",
      "Processing samples: 2200000 to 2300000\n",
      "Processing samples: 2300000 to 2400000\n",
      "Processing samples: 2400000 to 2500000\n",
      "Processing samples: 2500000 to 2600000\n",
      "Processing samples: 2600000 to 2700000\n",
      "Processing samples: 2700000 to 2800000\n",
      "Processing samples: 2800000 to 2900000\n",
      "Processing samples: 2900000 to 3000000\n",
      "Processing samples: 3000000 to 3100000\n",
      "Processing samples: 3100000 to 3200000\n",
      "Processing samples: 3200000 to 3300000\n",
      "Processing samples: 3300000 to 3400000\n",
      "Processing samples: 3400000 to 3500000\n",
      "Processing samples: 3500000 to 3600000\n",
      "Processing samples: 3600000 to 3700000\n",
      "Processing samples: 3700000 to 3800000\n",
      "Processing samples: 3800000 to 3900000\n",
      "Processing samples: 3900000 to 4000000\n",
      "Processing samples: 4000000 to 4100000\n",
      "Processing samples: 4100000 to 4200000\n",
      "Processing samples: 4200000 to 4300000\n",
      "Processing samples: 4300000 to 4400000\n",
      "Processing samples: 4400000 to 4500000\n",
      "Processing samples: 4500000 to 4600000\n",
      "Processing samples: 4600000 to 4700000\n",
      "Processing samples: 4700000 to 4800000\n",
      "Processing samples: 4800000 to 4900000\n",
      "Processing samples: 4900000 to 5000000\n",
      "Processing samples: 5000000 to 5100000\n",
      "Processing samples: 5100000 to 5200000\n",
      "Processing samples: 5200000 to 5300000\n",
      "Processing samples: 5300000 to 5400000\n",
      "Processing samples: 5400000 to 5500000\n",
      "Processing samples: 5500000 to 5600000\n",
      "Processing samples: 5600000 to 5700000\n",
      "Processing samples: 5700000 to 5800000\n",
      "Processing samples: 5800000 to 5900000\n",
      "Processing samples: 5900000 to 6000000\n",
      "Processing samples: 6000000 to 6100000\n",
      "Processing samples: 6100000 to 6200000\n",
      "Processing samples: 6200000 to 6300000\n",
      "Processing samples: 6300000 to 6400000\n",
      "Processing samples: 6400000 to 6500000\n",
      "Processing samples: 6500000 to 6600000\n",
      "Processing samples: 6600000 to 6700000\n",
      "Processing samples: 6700000 to 6800000\n",
      "Processing samples: 6800000 to 6900000\n",
      "Processing samples: 6900000 to 7000000\n",
      "Processing samples: 7000000 to 7100000\n",
      "Processing samples: 7100000 to 7200000\n",
      "Processing samples: 7200000 to 7300000\n",
      "Processing samples: 7300000 to 7400000\n",
      "Processing samples: 7400000 to 7500000\n",
      "Processing samples: 7500000 to 7600000\n",
      "Processing samples: 7600000 to 7700000\n",
      "Processing samples: 7700000 to 7800000\n",
      "Processing samples: 7800000 to 7900000\n",
      "Processing samples: 7900000 to 8000000\n",
      "Processing samples: 8000000 to 8100000\n",
      "Processing samples: 8100000 to 8200000\n",
      "Processing samples: 8200000 to 8300000\n",
      "Processing samples: 8300000 to 8400000\n",
      "Processing samples: 8400000 to 8500000\n",
      "Processing samples: 8500000 to 8600000\n",
      "Processing samples: 8600000 to 8700000\n",
      "Processing samples: 8700000 to 8800000\n",
      "Processing samples: 8800000 to 8900000\n",
      "Processing samples: 8900000 to 9000000\n",
      "Processing samples: 9000000 to 9100000\n",
      "Processing samples: 9100000 to 9200000\n",
      "Processing samples: 9200000 to 9300000\n",
      "Processing samples: 9300000 to 9400000\n",
      "Processing samples: 9400000 to 9500000\n",
      "Processing samples: 9500000 to 9600000\n",
      "Processing samples: 9600000 to 9700000\n",
      "Processing samples: 9700000 to 9800000\n",
      "Processing samples: 9800000 to 9900000\n",
      "Processing samples: 9900000 to 10000000\n",
      "Processing samples: 10000000 to 10100000\n",
      "Processing samples: 10100000 to 10200000\n",
      "Processing samples: 10200000 to 10300000\n",
      "Processing samples: 10300000 to 10400000\n",
      "Processing samples: 10400000 to 10500000\n",
      "Processing samples: 10500000 to 10600000\n",
      "Processing samples: 10600000 to 10700000\n",
      "Processing samples: 10700000 to 10800000\n",
      "Processing samples: 10800000 to 10900000\n",
      "Processing samples: 10900000 to 11000000\n",
      "Processing samples: 11000000 to 11100000\n",
      "Processing samples: 11100000 to 11200000\n",
      "Processing samples: 11200000 to 11300000\n",
      "Processing samples: 11300000 to 11400000\n",
      "Processing samples: 11400000 to 11500000\n",
      "Processing samples: 11500000 to 11600000\n",
      "Processing samples: 11600000 to 11700000\n",
      "Processing samples: 11700000 to 11800000\n",
      "Processing samples: 11800000 to 11900000\n",
      "Processing samples: 11900000 to 12000000\n",
      "Processing samples: 12000000 to 12100000\n",
      "Processing samples: 12100000 to 12200000\n",
      "Processing samples: 12200000 to 12300000\n",
      "Processing samples: 12300000 to 12400000\n",
      "Processing samples: 12400000 to 12500000\n",
      "Processing samples: 12500000 to 12600000\n",
      "Processing samples: 12600000 to 12700000\n",
      "Processing samples: 12700000 to 12800000\n",
      "Processing samples: 12800000 to 12900000\n",
      "Processing samples: 12900000 to 13000000\n",
      "Processing samples: 13000000 to 13100000\n",
      "Processing samples: 13100000 to 13200000\n",
      "Processing samples: 13200000 to 13300000\n",
      "Processing samples: 13300000 to 13400000\n",
      "Processing samples: 13400000 to 13500000\n",
      "Processing samples: 13500000 to 13600000\n",
      "Processing samples: 13600000 to 13700000\n",
      "Processing samples: 13700000 to 13800000\n",
      "Processing samples: 13800000 to 13900000\n",
      "Processing samples: 13900000 to 14000000\n",
      "Processing samples: 14000000 to 14100000\n",
      "Processing samples: 14100000 to 14200000\n",
      "Processing samples: 14200000 to 14300000\n",
      "Processing samples: 14300000 to 14400000\n",
      "Processing samples: 14400000 to 14500000\n",
      "Processing samples: 14500000 to 14600000\n",
      "Processing samples: 14600000 to 14700000\n",
      "Processing samples: 14700000 to 14800000\n",
      "Processing samples: 14800000 to 14900000\n",
      "Processing samples: 14900000 to 15000000\n",
      "Processing samples: 15000000 to 15100000\n",
      "Processing samples: 15100000 to 15200000\n",
      "Processing samples: 15200000 to 15300000\n",
      "Processing samples: 15300000 to 15400000\n",
      "Processing samples: 15400000 to 15500000\n",
      "Processing samples: 15500000 to 15600000\n",
      "Processing samples: 15600000 to 15700000\n",
      "Processing samples: 15700000 to 15800000\n",
      "Processing samples: 15800000 to 15900000\n",
      "Processing samples: 15900000 to 16000000\n",
      "Processing samples: 16000000 to 16100000\n",
      "Processing samples: 16100000 to 16200000\n",
      "Processing samples: 16200000 to 16300000\n",
      "Processing samples: 16300000 to 16400000\n",
      "Processing samples: 16400000 to 16500000\n",
      "Processing samples: 16500000 to 16600000\n",
      "Processing samples: 16600000 to 16700000\n",
      "Processing samples: 16700000 to 16800000\n",
      "Processing samples: 16800000 to 16900000\n",
      "Processing samples: 16900000 to 17000000\n",
      "Processing samples: 17000000 to 17100000\n",
      "Processing samples: 17100000 to 17200000\n",
      "Data Loaded Successfully:\n",
      "   Year State_Abbr State_FIPS County_FIPS  Race  Origin  Sex  Age  Population\n",
      "0  2009         AL         01         001     1       9    1    0         284\n",
      "1  2009         AL         01         001     1       9    1    1        1195\n",
      "2  2009         AL         01         001     1       9    1    2        1553\n",
      "3  2009         AL         01         001     1       9    1    3        1697\n",
      "4  2009         AL         01         001     1       9    1    4        1765\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5174919 entries, 0 to 5174918\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   Year         int64 \n",
      " 1   State_Abbr   object\n",
      " 2   State_FIPS   object\n",
      " 3   County_FIPS  object\n",
      " 4   Race         int64 \n",
      " 5   Origin       int64 \n",
      " 6   Sex          int64 \n",
      " 7   Age          int64 \n",
      " 8   Population   int64 \n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 355.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "col_specs = [\n",
    "    (0, 4),    # Year\n",
    "    (4, 6),    # State Postal Abbreviation\n",
    "    (6, 8),    # State FIPS\n",
    "    (8, 11),   # County FIPS\n",
    "    (13, 14),  # Race (Notice skip of indices 11-13)\n",
    "    (14, 15),  # Origin\n",
    "    (15, 16),  # Sex\n",
    "    (16, 18),  # Age\n",
    "    (18, 26)   # Population\n",
    "]\n",
    "\n",
    "names = [\n",
    "    'Year', \n",
    "    'State_Abbr', \n",
    "    'State_FIPS', \n",
    "    'County_FIPS', \n",
    "    'Race', \n",
    "    'Origin', \n",
    "    'Sex', \n",
    "    'Age', \n",
    "    'Population'\n",
    "]\n",
    "\n",
    "# Define data types to ensure FIPS codes retain leading zeros\n",
    "# and numeric fields are parsed correctly\n",
    "dtype_mapping = {\n",
    "    'Year': int,\n",
    "    'State_Abbr': str,\n",
    "    'State_FIPS': str, \n",
    "    'County_FIPS': str,\n",
    "    'Race': int,\n",
    "    'Origin': int,\n",
    "    'Sex': int,\n",
    "    'Age': int,\n",
    "    'Population': int\n",
    "}\n",
    "\n",
    "print(\"Starting...\")\n",
    "chunk_size = 100000\n",
    "chunks = []\n",
    "reader = pd.read_fwf(\n",
    "    '../../data/pop.txt',\n",
    "    colspecs=col_specs,\n",
    "    names=names,\n",
    "    dtype=dtype_mapping,\n",
    "    header=None,\n",
    "    chunksize = chunk_size\n",
    "    )\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    print(f\"Processing samples: {i*chunk_size} to {(i+1)*chunk_size}\", end='\\r')\n",
    "    filtered_chunk = chunk[chunk['Year'] >= 2009]\n",
    "    chunks.append(filtered_chunk)\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "if df is not None:\n",
    "    df.to_csv('../../data/pop.csv', index=False)\n",
    "    df.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024d01c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIPS</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <td>autauga</td>\n",
       "      <td>baldwin</td>\n",
       "      <td>barbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food_Insecurity_Rate</th>\n",
       "      <td>0.156</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Food_Insecure_Persons</th>\n",
       "      <td>8620.0</td>\n",
       "      <td>26860.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low_Threshold_State</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low_Threshold_Type</th>\n",
       "      <td>SNAP</td>\n",
       "      <td>SNAP</td>\n",
       "      <td>SNAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High_Threshold_State</th>\n",
       "      <td>1.85</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High_Threshold_Type</th>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "      <td>Other Nutrition Program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_FI_Below_Low_Threshold</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_FI_Between_Thresholds</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_FI_Above_High_Threshold</th>\n",
       "      <td>0.405</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Child_Food_Insecurity_Rate</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Food_Insecure_Children</th>\n",
       "      <td>2870.0</td>\n",
       "      <td>7710.0</td>\n",
       "      <td>1740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_FI_Children_Below_185FPL</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pct_FI_Children_Above_185FPL</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cost_Per_Meal</th>\n",
       "      <td>3.33</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual_Food_Budget_Shortfall</th>\n",
       "      <td>4857000.0</td>\n",
       "      <td>16274000.0</td>\n",
       "      <td>2988000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  \\\n",
       "Year                                             2018   \n",
       "FIPS                                           1001.0   \n",
       "County                                        autauga   \n",
       "State                                              AL   \n",
       "Food_Insecurity_Rate                            0.156   \n",
       "Num_Food_Insecure_Persons                      8620.0   \n",
       "Low_Threshold_State                               1.3   \n",
       "Low_Threshold_Type                               SNAP   \n",
       "High_Threshold_State                             1.85   \n",
       "High_Threshold_Type           Other Nutrition Program   \n",
       "Pct_FI_Below_Low_Threshold                      0.462   \n",
       "Pct_FI_Between_Thresholds                       0.132   \n",
       "Pct_FI_Above_High_Threshold                     0.405   \n",
       "Child_Food_Insecurity_Rate                      0.214   \n",
       "Num_Food_Insecure_Children                     2870.0   \n",
       "Pct_FI_Children_Below_185FPL                     0.69   \n",
       "Pct_FI_Children_Above_185FPL                     0.31   \n",
       "Cost_Per_Meal                                    3.33   \n",
       "Annual_Food_Budget_Shortfall                4857000.0   \n",
       "\n",
       "                                                    1                        2  \n",
       "Year                                             2018                     2018  \n",
       "FIPS                                           1003.0                   1005.0  \n",
       "County                                        baldwin                  barbour  \n",
       "State                                              AL                       AL  \n",
       "Food_Insecurity_Rate                            0.129                    0.219  \n",
       "Num_Food_Insecure_Persons                     26860.0                   5650.0  \n",
       "Low_Threshold_State                               1.3                      1.3  \n",
       "Low_Threshold_Type                               SNAP                     SNAP  \n",
       "High_Threshold_State                             1.85                     1.85  \n",
       "High_Threshold_Type           Other Nutrition Program  Other Nutrition Program  \n",
       "Pct_FI_Below_Low_Threshold                      0.371                    0.651  \n",
       "Pct_FI_Between_Thresholds                       0.187                    0.108  \n",
       "Pct_FI_Above_High_Threshold                     0.442                    0.241  \n",
       "Child_Food_Insecurity_Rate                      0.169                     0.32  \n",
       "Num_Food_Insecure_Children                     7710.0                   1740.0  \n",
       "Pct_FI_Children_Below_185FPL                     0.74                     0.76  \n",
       "Pct_FI_Children_Above_185FPL                     0.27                     0.25  \n",
       "Cost_Per_Meal                                    3.58                     3.12  \n",
       "Annual_Food_Budget_Shortfall               16274000.0                2988000.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '../../data/MMG_county_df_clean.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd8814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Running CBP Combiner (this may take a moment)...\n"
     ]
    }
   ],
   "source": [
    "def master_merge():\n",
    "    print(\"1. Running CBP Combiner (this may take a moment)...\")\n",
    "    try:\n",
    "        cbp_df = pd.read_csv('cbp_data.csv', low_memory=True)\n",
    "        \n",
    "        print(\"Loading context datasets (Population, Econ, MMG)...\")\n",
    "        pop = pd.read_csv('../../data/pop.csv')\n",
    "        mmg = pd.read_csv('../../data/MMG_county_df_clean.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading CSVs: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- STEP 3: Standardize Linking Keys (FIPS & Year) ---\n",
    "    print(\"3. Standardizing FIPS codes and Years...\")\n",
    "\n",
    "    # A. Standardize POP Keys\n",
    "    # Ensure State is 2 digits, County is 3 digits\n",
    "    pop['FIPS'] = pop['State_FIPS'].astype(str).str.zfill(2) + \\\n",
    "                  pop['County_FIPS'].astype(str).str.zfill(3)\n",
    "    pop.rename(columns={'Year': 'YEAR'}, inplace=True)\n",
    "\n",
    "    # C. Standardize MMG Keys\n",
    "    # Remove decimals if they exist (1001.0 -> 1001) then pad\n",
    "    mmg['FIPS'] = mmg['FIPS'].astype(float).astype(int).astype(str).str.zfill(5)\n",
    "    mmg.rename(columns={'Year': 'YEAR'}, inplace=True)\n",
    "\n",
    "    # --- STEP 4: Create Unified Context Table ---\n",
    "    print(\"4. Creating County Context Table (Merging Pop, MMG, Econ)...\")\n",
    "    \n",
    "    # Merge Population and Food Insecurity on YEAR and FIPS\n",
    "    # 'outer' ensures we keep counties even if one dataset is missing a year\n",
    "    county_context = pd.merge(pop, mmg, on=['YEAR', 'FIPS'], how='outer', indicator=True)\n",
    "    print(\"Indicator Column:\", county_context['_merge'].value_counts())\n",
    "\n",
    "    print(f\"   Context Table Shape: {county_context.shape}\")\n",
    "\n",
    "    # --- STEP 5: The Master Merge ---\n",
    "    print(\"5. Performing Master Merge (CBP + Context)...\")\n",
    "    \n",
    "    # We merge CBP (Left) with Context (Right). \n",
    "    # Using 'left' ensures we keep every Industry record from CBP.\n",
    "    final_df = pd.merge(\n",
    "        cbp_df, \n",
    "        county_context, \n",
    "        on=['YEAR', 'FIPS'], \n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    print(\"Indicator Column:\", final_df['_merge'].value_counts())\n",
    "    print(f\"   Final Shape: {final_df.shape}\")\n",
    "\n",
    "    # --- STEP 6: Save Result ---\n",
    "    output_filename = 'final_master_dataset.csv'\n",
    "    print(f\"6. Saving final dataset to {output_filename}...\")\n",
    "    \n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    print(\"SUCCESS!\")\n",
    "    print(f\"Saved to: {output_filename}\")\n",
    "    print(f\"Final Shape: {final_df.shape}\")\n",
    "    print(\"=\"*40)\n",
    "    print(final_df.head())\n",
    "\n",
    "\n",
    "master_merge()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pred_modeling_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
